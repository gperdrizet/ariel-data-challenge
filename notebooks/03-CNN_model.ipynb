{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30cbf344",
   "metadata": {},
   "source": [
    "# CNN model\n",
    "\n",
    "## Notebook set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0e47803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /mnt/arkk/kaggle/ariel-data-challenge\n"
     ]
    }
   ],
   "source": [
    "# Set notebook root to project root\n",
    "from helper_functions import set_project_root\n",
    "\n",
    "set_project_root()\n",
    "\n",
    "# Standard library imports\n",
    "import random\n",
    "from functools import partial\n",
    "\n",
    "# Third party imports\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Local imports\n",
    "from ariel_data_preprocessing.utils import load_masked_frames\n",
    "import configuration as config\n",
    "\n",
    "wavelengths = 283\n",
    "sample_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc846628",
   "metadata": {},
   "source": [
    "## 1. Data preparation\n",
    "\n",
    "### 1.1. Load planet list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2828f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1100 planets in training data.\n"
     ]
    }
   ],
   "source": [
    "# Load corrected/extracted data for a sample planet\n",
    "with h5py.File(f'{config.PROCESSED_DATA_DIRECTORY}/train.h5', 'r') as hdf:\n",
    "    planet_ids = list(hdf.keys())\n",
    "\n",
    "print(f'Found {len(planet_ids)} planets in training data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915ce92f",
   "metadata": {},
   "source": [
    "### 1.2. Split planets into training & validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb4e151a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training planets: 550\n",
      "Validation planets: 550\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(planet_ids)\n",
    "\n",
    "training_planet_ids = planet_ids[:len(planet_ids) // 2]\n",
    "validation_planet_ids = planet_ids[len(planet_ids) // 2:]\n",
    "\n",
    "print(f'Training planets: {len(training_planet_ids)}')\n",
    "print(f'Validation planets: {len(validation_planet_ids)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e56c6c8",
   "metadata": {},
   "source": [
    "## 2. Data generator\n",
    "\n",
    "### 2.1. Data loader function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1a770dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(planet_ids: list, data_file: str, sample_size: int = 100):\n",
    "    '''Generator that yields signal, spectrum pairs for training/validation/testing.\n",
    "\n",
    "    Args:\n",
    "        planet_ids (list): List of planet IDs to include in the generator.\n",
    "        data_file (str): Path to the HDF5 file containing the data.\n",
    "        sample_size (int, optional): Number of frames to draw from each planet. Defaults to 100.\n",
    "    '''\n",
    "\n",
    "    with h5py.File(data_file, 'r') as hdf:\n",
    "\n",
    "        while True:\n",
    "            np.random.shuffle(planet_ids)\n",
    "            \n",
    "            for planet_id in planet_ids:\n",
    "\n",
    "                signal = hdf[planet_id]['signal'][:]\n",
    "                spectrum = hdf[planet_id]['spectrum'][:]\n",
    "\n",
    "                indices = random.sample(range(signal.shape[0]), sample_size)\n",
    "                sample = signal[sorted(indices), :]\n",
    "\n",
    "                yield sample, spectrum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e961fa07",
   "metadata": {},
   "source": [
    "### 2.2. Prefill the arguments to `data_loader()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d22cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_generator = partial(\n",
    "    data_loader,\n",
    "    planet_ids=training_planet_ids,\n",
    "    data_file=f'{config.PROCESSED_DATA_DIRECTORY}/train.h5',\n",
    "    sample_size=100\n",
    ")\n",
    "\n",
    "validation_data_generator = partial(\n",
    "    data_loader,\n",
    "    planet_ids=validation_planet_ids,\n",
    "    data_file=f'{config.PROCESSED_DATA_DIRECTORY}/train.h5',\n",
    "    sample_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e49150",
   "metadata": {},
   "source": [
    "### 2.3. Create TF datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9bd92d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.from_generator(\n",
    "    training_data_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(sample_size, wavelengths), dtype=tf.float64),\n",
    "        tf.TensorSpec(shape=(wavelengths), dtype=tf.float64)\n",
    "    )\n",
    ")\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_generator(\n",
    "    validation_data_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(sample_size, wavelengths), dtype=tf.float64),\n",
    "        tf.TensorSpec(shape=(wavelengths), dtype=tf.float64)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b413f682",
   "metadata": {},
   "source": [
    "### 2.4. Manually check batch shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e9fa700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal batch shape: (4, 100, 283)\n",
      "Spectrum batch shape: (4, 283)\n"
     ]
    }
   ],
   "source": [
    "batch = training_dataset.batch(4)\n",
    "signals, spectrums = next(iter(batch))\n",
    "\n",
    "print(f'Signal batch shape: {signals.shape}')\n",
    "print(f'Spectrum batch shape: {spectrums.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d586e99",
   "metadata": {},
   "source": [
    "## 3. CNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
