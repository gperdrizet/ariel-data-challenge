{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98dee706",
   "metadata": {},
   "source": [
    "# ARIS-CH0 signal EDA\n",
    "\n",
    "## Notebooks set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a00e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set notebook root to project root\n",
    "from helper_functions import set_project_root\n",
    "\n",
    "set_project_root()\n",
    "\n",
    "# Standard library imports\n",
    "from pathlib import Path\n",
    "\n",
    "# Third party imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Internal imports\n",
    "import configuration as config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc71542",
   "metadata": {},
   "source": [
    "## 1. Single planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff654a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "airs_file = f'{config.RAW_DATA_DIRECTORY}/train/{config.SAMPLE_PLANET}/AIRS-CH0_signal_0.parquet'\n",
    "print(f'Example AIRS-CH0 signal file path: {airs_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71769b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Parquet file into a PyArrow Table\n",
    "signal = pd.read_parquet(airs_file).to_numpy().reshape(11250, 32, 356)\n",
    "print(f'Raw signal shape: {signal.shape}')\n",
    "print(f'Raw frame shape: {signal[0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997b79c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the frames - see here: https://www.kaggle.com/code/gordonyip/calibrating-and-binning-ariel-data\n",
    "cut_inf, cut_sup = 39, 321\n",
    "signal = signal[:, :, cut_inf:cut_sup]\n",
    "print(f'Cropped signal shape: {signal.shape}')\n",
    "print(f'Cropped frame shape: {signal[0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0b8cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first few frames\n",
    "n_frames = 5\n",
    "fig, axs = plt.subplots(n_frames, 1, figsize=(10, n_frames))\n",
    "axs = axs.flatten()\n",
    "\n",
    "fig.suptitle(f'First {n_frames} cropped frames of AIRS-CH0 signal for planet {config.SAMPLE_PLANET}')\n",
    "\n",
    "for i in range(n_frames):\n",
    "    frame = signal[i]        \n",
    "    frame = frame.astype(float) / np.mean(frame.astype(float))\n",
    "    axs[i].imshow(frame)\n",
    "    axs[i].axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/EDA/01.3-AIRS_sample_frames.jpg', dpi=config.STD_FIG_DPI, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dc2276",
   "metadata": {},
   "source": [
    "OK - I get it. Those smears are spectra - Ariel must put the signal through a grism or prism or something. Nice hint from the competition organizers about cropping the frames with `[:, :, 39:321]`, now we have a 1 to 1 correspondence between the pixels across the observed spectra and the wavelengths (though let's not assume no overlap...). One **more** hint they dropped in the [preprocessing notebook](https://www.kaggle.com/code/gordonyip/calibrating-and-binning-ariel-data) they shared is: '*Data reduction is crucial in astronomical observations*'. We should be able to isolate the 'strip' that contains the actual data. I also now understand why they included the guidance camera frames - it will probably make it much easier to spot exoplanet transits than trying to use these IR spectra smears.\n",
    "\n",
    "Still not sure how exactly to get the uncertainties - some kind of bootstrapping probably.\n",
    "\n",
    "Here's the tentative plan:\n",
    "\n",
    "1. Figure out how to efficiently spot transits in the FGS data.\n",
    "2. Use transit info from FGS data to isolate transit spectral data from AIRS.\n",
    "3. Use some kind of bootstrapping or ensemble method to learn the spectrum and get uncertainties.\n",
    "\n",
    "Last, save a frame for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaa3e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_planet = f'{config.DATA_DIRECTORY}/raw/train/{config.SAMPLE_PLANET}'\n",
    "Path(test_planet).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "signal = pd.read_parquet(f'{test_planet}/AIRS-CH0_signal_0.parquet').to_numpy().reshape(11250, 32, 356)\n",
    "test_frame = signal[:50]\n",
    "test_frame = test_frame.flatten()\n",
    "\n",
    "test_planet = f'./tests/test_data/raw/train/{config.SAMPLE_PLANET}'\n",
    "Path(test_planet).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(f'{test_planet}/AIRS-CH0_signal_0.parquet', 'wb') as f:\n",
    "    pd.DataFrame(test_frame).to_parquet(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
